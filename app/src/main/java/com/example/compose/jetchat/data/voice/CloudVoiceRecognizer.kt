package com.example.compose.jetchat.data.voice

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.example.compose.jetchat.config.AppConfig
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.withContext
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.RequestBody.Companion.asRequestBody
import org.json.JSONObject
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.util.concurrent.TimeUnit

/**
 * äº‘ç«¯è¯­éŸ³è¯†åˆ«æœåŠ¡
 * 
 * ä½¿ç”¨ OpenAI Whisper API è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
 * ç±»ä¼¼äºå¾®ä¿¡ã€QQã€Kimi çš„è¯­éŸ³è¯†åˆ«åŠŸèƒ½
 * 
 * ä¼˜ç‚¹ï¼š
 * 1. ä¸ä¾èµ–è®¾å¤‡æœ¬åœ°è¯­éŸ³è¯†åˆ«å¼•æ“
 * 2. æ”¯æŒæ‰€æœ‰ Android è®¾å¤‡ï¼ˆåŒ…æ‹¬æ¨¡æ‹Ÿå™¨ï¼‰
 * 3. è¯†åˆ«å‡†ç¡®ç‡é«˜
 * 4. æ”¯æŒå¤šç§è¯­è¨€
 */
class CloudVoiceRecognizer(private val context: Context) {
    
    companion object {
        private const val TAG = "CloudVoiceRecognizer"
        
        // éŸ³é¢‘å‚æ•°
        private const val SAMPLE_RATE = 16000  // Whisper æ¨è 16kHz
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        
        // Whisper API
        private const val WHISPER_API_URL = "https://api.vectorengine.ai/v1/audio/transcriptions"
    }
    
    private var audioRecord: AudioRecord? = null
    private var isRecording = false
    private var recordingFile: File? = null
    
    // ä¿å­˜æœ€åä¸€æ¬¡è¯†åˆ«ç»“æœ
    private var lastRecognitionResult: String? = null
    private var lastAudioPath: String? = null
    private var lastAudioDuration: Long = 0L
    private var recordingStartTime: Long = 0L
    
    private val _isListening = MutableStateFlow(false)
    val isListening: StateFlow<Boolean> = _isListening
    
    private val _isRecognizing = MutableStateFlow(false)
    val isRecognizing: StateFlow<Boolean> = _isRecognizing
    
    private val _transcription = MutableStateFlow("")
    val transcription: StateFlow<String> = _transcription
    
    private val _error = MutableStateFlow<String?>(null)
    val error: StateFlow<String?> = _error
    
    private val okHttpClient = OkHttpClient.Builder()
        .connectTimeout(30, TimeUnit.SECONDS)
        .readTimeout(60, TimeUnit.SECONDS)  // è¯­éŸ³è¯†åˆ«å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
        .writeTimeout(60, TimeUnit.SECONDS)
        .build()
    
    /**
     * å¼€å§‹å½•éŸ³
     */
    @Suppress("MissingPermission")
    fun startRecording() {
        if (_isListening.value) {
            Log.w(TAG, "å½•éŸ³å·²åœ¨è¿›è¡Œä¸­")
            return
        }
        
        try {
            // åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            recordingFile = File(context.cacheDir, "voice_${System.currentTimeMillis()}.wav")
            
            // è®¡ç®—ç¼“å†²åŒºå¤§å°
            val bufferSize = AudioRecord.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            )
            
            // åˆ›å»º AudioRecord
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                bufferSize
            )
            
            // å¼€å§‹å½•éŸ³
            audioRecord?.startRecording()
            isRecording = true
            _isListening.value = true
            _error.value = null
            recordingStartTime = System.currentTimeMillis()
            
            Log.d(TAG, "âœ“ å¼€å§‹å½•éŸ³: ${recordingFile?.name}")
            
            // åœ¨åå°çº¿ç¨‹å½•éŸ³
            Thread {
                recordAudioToFile()
            }.start()
            
        } catch (e: Exception) {
            Log.e(TAG, "âœ— å½•éŸ³å¯åŠ¨å¤±è´¥: ${e.message}", e)
            _error.value = "å½•éŸ³å¯åŠ¨å¤±è´¥: ${e.message}"
            _isListening.value = false
        }
    }
    
    /**
     * åœæ­¢å½•éŸ³å¹¶å‘é€åˆ°äº‘ç«¯è¯†åˆ«
     */
    suspend fun stopRecordingAndRecognize() {
        if (!_isListening.value) {
            Log.w(TAG, "å½•éŸ³æœªåœ¨è¿›è¡Œä¸­")
            return
        }
        
        try {
            // åœæ­¢å½•éŸ³
            isRecording = false
            audioRecord?.stop()
            audioRecord?.release()
            audioRecord = null
            
            _isListening.value = false
            _isRecognizing.value = true  // å¼€å§‹è¯†åˆ«çŠ¶æ€
            
            Log.d(TAG, "âœ“ å½•éŸ³å·²åœæ­¢ï¼Œå‡†å¤‡å‘é€åˆ°äº‘ç«¯è¯†åˆ«...")
            
            // æ£€æŸ¥æ–‡ä»¶
            val file = recordingFile
            if (file == null || !file.exists() || file.length() == 0L) {
                _error.value = "å½•éŸ³æ–‡ä»¶æ— æ•ˆ"
                Log.e(TAG, "âœ— å½•éŸ³æ–‡ä»¶æ— æ•ˆ")
                _isRecognizing.value = false
                return
            }
            
            Log.d(TAG, "âœ“ å½•éŸ³æ–‡ä»¶: ${file.name}, å¤§å°: ${file.length()} bytes")
            
            // å‘é€åˆ° Whisper API è¿›è¡Œè¯†åˆ«
            val transcriptionText = recognizeAudio(file)
            
            _isRecognizing.value = false  // è¯†åˆ«å®Œæˆ
            
            if (transcriptionText.isNotEmpty()) {
                _transcription.value = transcriptionText
                // ä¿å­˜è¯†åˆ«ç»“æœ
                lastRecognitionResult = transcriptionText
                lastAudioPath = file.absolutePath
                lastAudioDuration = System.currentTimeMillis() - recordingStartTime
                Log.d(TAG, "âœ“ è¯†åˆ«æˆåŠŸ: $transcriptionText")
            } else {
                _error.value = "è¯†åˆ«ç»“æœä¸ºç©º"
                Log.e(TAG, "âœ— è¯†åˆ«ç»“æœä¸ºç©º")
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âœ— åœæ­¢å½•éŸ³å¤±è´¥: ${e.message}", e)
            _error.value = "åœæ­¢å½•éŸ³å¤±è´¥: ${e.message}"
        } finally {
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            recordingFile?.delete()
            recordingFile = null
        }
    }
    
    /**
     * å°†éŸ³é¢‘å½•åˆ¶åˆ°æ–‡ä»¶
     */
    private fun recordAudioToFile() {
        val file = recordingFile ?: return
        val bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT)
        val buffer = ByteArray(bufferSize)
        
        try {
            FileOutputStream(file).use { outputStream ->
                // å†™å…¥ WAV æ–‡ä»¶å¤´ï¼ˆå ä½ï¼‰
                writeWavHeader(outputStream, 0, SAMPLE_RATE, 1, 16)
                
                var totalBytes = 0
                
                // å½•éŸ³å¾ªç¯
                while (isRecording) {
                    val read = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                    if (read > 0) {
                        outputStream.write(buffer, 0, read)
                        totalBytes += read
                    }
                }
                
                // æ›´æ–° WAV æ–‡ä»¶å¤´
                outputStream.flush()
                updateWavHeader(file, totalBytes)
                
                Log.d(TAG, "âœ“ å½•éŸ³å®Œæˆï¼Œæ€»å­—èŠ‚æ•°: $totalBytes")
            }
        } catch (e: Exception) {
            Log.e(TAG, "âœ— å½•éŸ³å†™å…¥æ–‡ä»¶å¤±è´¥: ${e.message}", e)
            _error.value = "å½•éŸ³å†™å…¥å¤±è´¥: ${e.message}"
        }
    }
    
    /**
     * å†™å…¥ WAV æ–‡ä»¶å¤´
     */
    private fun writeWavHeader(
        out: FileOutputStream,
        dataLength: Int,
        sampleRate: Int,
        channels: Int,
        bitsPerSample: Int
    ) {
        val byteRate = sampleRate * channels * bitsPerSample / 8
        val blockAlign = (channels * bitsPerSample / 8).toShort()
        
        val header = ByteArray(44)
        
        // RIFF chunk
        header[0] = 'R'.code.toByte()
        header[1] = 'I'.code.toByte()
        header[2] = 'F'.code.toByte()
        header[3] = 'F'.code.toByte()
        
        val chunkSize = 36 + dataLength
        header[4] = (chunkSize and 0xff).toByte()
        header[5] = ((chunkSize shr 8) and 0xff).toByte()
        header[6] = ((chunkSize shr 16) and 0xff).toByte()
        header[7] = ((chunkSize shr 24) and 0xff).toByte()
        
        // WAVE format
        header[8] = 'W'.code.toByte()
        header[9] = 'A'.code.toByte()
        header[10] = 'V'.code.toByte()
        header[11] = 'E'.code.toByte()
        
        // fmt chunk
        header[12] = 'f'.code.toByte()
        header[13] = 'm'.code.toByte()
        header[14] = 't'.code.toByte()
        header[15] = ' '.code.toByte()
        
        header[16] = 16  // fmt chunk size
        header[17] = 0
        header[18] = 0
        header[19] = 0
        
        header[20] = 1  // PCM format
        header[21] = 0
        
        header[22] = channels.toByte()
        header[23] = 0
        
        header[24] = (sampleRate and 0xff).toByte()
        header[25] = ((sampleRate shr 8) and 0xff).toByte()
        header[26] = ((sampleRate shr 16) and 0xff).toByte()
        header[27] = ((sampleRate shr 24) and 0xff).toByte()
        
        header[28] = (byteRate and 0xff).toByte()
        header[29] = ((byteRate shr 8) and 0xff).toByte()
        header[30] = ((byteRate shr 16) and 0xff).toByte()
        header[31] = ((byteRate shr 24) and 0xff).toByte()
        
        header[32] = (blockAlign.toInt() and 0xff).toByte()
        header[33] = ((blockAlign.toInt() shr 8) and 0xff).toByte()
        
        header[34] = bitsPerSample.toByte()
        header[35] = 0
        
        // data chunk
        header[36] = 'd'.code.toByte()
        header[37] = 'a'.code.toByte()
        header[38] = 't'.code.toByte()
        header[39] = 'a'.code.toByte()
        
        header[40] = (dataLength and 0xff).toByte()
        header[41] = ((dataLength shr 8) and 0xff).toByte()
        header[42] = ((dataLength shr 16) and 0xff).toByte()
        header[43] = ((dataLength shr 24) and 0xff).toByte()
        
        out.write(header)
    }
    
    /**
     * æ›´æ–° WAV æ–‡ä»¶å¤´ä¸­çš„æ•°æ®é•¿åº¦
     */
    private fun updateWavHeader(file: File, dataLength: Int) {
        try {
            java.io.RandomAccessFile(file, "rw").use { raf ->
                // æ›´æ–° RIFF chunk size (offset 4)
                raf.seek(4)
                val chunkSize = 36 + dataLength
                raf.write(byteArrayOf(
                    (chunkSize and 0xff).toByte(),
                    ((chunkSize shr 8) and 0xff).toByte(),
                    ((chunkSize shr 16) and 0xff).toByte(),
                    ((chunkSize shr 24) and 0xff).toByte()
                ))
                
                // æ›´æ–° data chunk size (offset 40)
                raf.seek(40)
                raf.write(byteArrayOf(
                    (dataLength and 0xff).toByte(),
                    ((dataLength shr 8) and 0xff).toByte(),
                    ((dataLength shr 16) and 0xff).toByte(),
                    ((dataLength shr 24) and 0xff).toByte()
                ))
            }
        } catch (e: Exception) {
            Log.e(TAG, "âœ— æ›´æ–° WAV æ–‡ä»¶å¤´å¤±è´¥: ${e.message}", e)
        }
    }
    
    /**
     * è°ƒç”¨ Whisper API è¯†åˆ«éŸ³é¢‘
     */
    private suspend fun recognizeAudio(file: File): String = withContext(Dispatchers.IO) {
        try {
            Log.d(TAG, "â†’ å‘é€éŸ³é¢‘åˆ° Whisper API...")
            
            // æ„å»º multipart è¯·æ±‚
            val requestBody = MultipartBody.Builder()
                .setType(MultipartBody.FORM)
                .addFormDataPart(
                    "file",
                    file.name,
                    file.asRequestBody("audio/wav".toMediaTypeOrNull())
                )
                .addFormDataPart("model", "whisper-1")
                .addFormDataPart("language", "zh")  // ä¸­æ–‡
                .addFormDataPart("response_format", "json")
                .build()
            
            val request = Request.Builder()
                .url(WHISPER_API_URL)
                .addHeader("Authorization", "Bearer ${AppConfig.API_KEY}")
                .post(requestBody)
                .build()
            
            val response = okHttpClient.newCall(request).execute()
            val responseBody = response.body?.string()
            
            Log.d(TAG, "â† Whisper API å“åº”: HTTP ${response.code}")
            
            if (!response.isSuccessful) {
                val errorMsg = "è¯†åˆ«å¤±è´¥: HTTP ${response.code}"
                Log.e(TAG, "âœ— $errorMsg\nå“åº”: $responseBody")
                _error.value = errorMsg
                return@withContext ""
            }
            
            // è§£æå“åº”
            val jsonResponse = JSONObject(responseBody ?: "{}")
            val text = jsonResponse.optString("text", "")
            
            if (text.isEmpty()) {
                Log.w(TAG, "âš  è¯†åˆ«ç»“æœä¸ºç©º")
            }
            
            return@withContext text
            
        } catch (e: IOException) {
            Log.e(TAG, "âœ— ç½‘ç»œè¯·æ±‚å¤±è´¥: ${e.message}", e)
            
            // åˆ¤æ–­æ˜¯å¦ä¸ºè¿æ¥è¶…æ—¶æˆ–ç½‘ç»œä¸é€š
            val errorMsg = when {
                e.message?.contains("failed to connect") == true -> 
                    "å¤–ç½‘è®¿é—®ç¹å¿™ï¼Œè¯·ç¨åå†è¯• ğŸŒ"
                e.message?.contains("timeout") == true -> 
                    "ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯• â±ï¸"
                e.message?.contains("Unable to resolve host") == true -> 
                    "æ— æ³•è¿æ¥æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ ğŸ“¡"
                else -> 
                    "ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            }
            
            _error.value = errorMsg
            return@withContext ""
        } catch (e: Exception) {
            Log.e(TAG, "âœ— è¯†åˆ«å¤±è´¥: ${e.message}", e)
            _error.value = "è¯­éŸ³è¯†åˆ«å¤±è´¥: ${e.message}"
            return@withContext ""
        }
    }
    
    /**
     * è·å–å½•éŸ³æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè¯­éŸ³æ¶ˆæ¯æ˜¾ç¤ºï¼‰
     */
    fun getRecordingFilePath(): String? {
        return recordingFile?.absolutePath
    }
    
    /**
     * è·å–å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
     */
    fun getRecordingDuration(): Int {
        val file = recordingFile ?: return 0
        if (!file.exists()) return 0
        
        return try {
            val mediaPlayer = android.media.MediaPlayer()
            mediaPlayer.setDataSource(file.absolutePath)
            mediaPlayer.prepare()
            val duration = (mediaPlayer.duration / 1000).coerceAtLeast(1)
            mediaPlayer.release()
            duration
        } catch (e: Exception) {
            Log.e(TAG, "è·å–å½•éŸ³æ—¶é•¿å¤±è´¥: ${e.message}", e)
            1
        }
    }
    
    /**
     * å–æ¶ˆå½•éŸ³
     */
    fun cancelRecording() {
        isRecording = false
        audioRecord?.stop()
        audioRecord?.release()
        audioRecord = null
        _isListening.value = false
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        recordingFile?.delete()
        recordingFile = null
        
        Log.d(TAG, "âœ“ å½•éŸ³å·²å–æ¶ˆ")
    }
    
    /**
     * è·å–æœ€åä¸€æ¬¡è¯†åˆ«ç»“æœ
     */
    fun getLastRecognitionResult(): String? = lastRecognitionResult
    
    /**
     * è·å–æœ€åä¸€æ¬¡å½•éŸ³æ–‡ä»¶è·¯å¾„
     */
    fun getLastAudioPath(): String? = lastAudioPath
    
    /**
     * è·å–æœ€åä¸€æ¬¡å½•éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
     */
    fun getLastAudioDuration(): Long = lastAudioDuration
    
    /**
     * æ¸…ç†èµ„æº
     */
    fun cleanup() {
        cancelRecording()
        Log.d(TAG, "âœ“ èµ„æºå·²æ¸…ç†")
    }
}
